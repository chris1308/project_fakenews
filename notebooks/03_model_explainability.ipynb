{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nDSKEbAaZHM"
      },
      "outputs": [],
      "source": [
        "final_model = rf_model # rf model being chosen for higher accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use lime for explainability purpose\n",
        "!pip install lime"
      ],
      "metadata": {
        "id": "g5sK8djlagzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = tfidf.get_feature_names_out()  # numpy array of feature names\n",
        "print(feature_names)"
      ],
      "metadata": {
        "id": "KaMQzgpjal4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature importances visualization using matplotlib horizontal bar chart\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "importances = final_model.feature_importances_\n",
        "top_n = 30\n",
        "indices = np.argsort(importances)[-top_n:]\n",
        "\n",
        "top_features = feature_names[indices]\n",
        "top_scores = importances[indices]\n",
        "\n",
        "# print (ascending)\n",
        "for w, s in zip(top_features[::-1], top_scores[::-1]):\n",
        "    print(f\"{w}: {s:.6f}\")\n",
        "\n",
        "# bar plot\n",
        "plt.figure(figsize=(8,10))\n",
        "plt.barh(top_features, top_scores)\n",
        "plt.title(\"Random Forest - Top Feature Importances\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save figure\n",
        "plt.savefig(\"rf_top_importances.png\", dpi=200, bbox_inches=\"tight\")\n"
      ],
      "metadata": {
        "id": "jY0EzugHan16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LIME =LIME explains why the model predicted a certain label for a single article.\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "# Create a pipeline that accepts raw text\n",
        "pipeline = make_pipeline(tfidf, rf_model)\n",
        "\n",
        "# Class names\n",
        "class_names = ['REAL', 'FAKE']\n",
        "\n",
        "explainer = LimeTextExplainer(class_names=class_names)\n",
        "\n",
        "# choose an index in test set to explain\n",
        "idx = 6  # can be adjusted to any test sample index\n",
        "text_to_explain = X_test.iloc[idx]  # row[idx] from X_test\n",
        "\n",
        "exp = explainer.explain_instance(text_to_explain, pipeline.predict_proba, num_features=10)\n",
        "# show HTML in notebook\n",
        "exp.show_in_notebook(text=True)\n",
        "\n",
        "# print the explanation as list (word, weight)\n",
        "# print(exp.as_list())\n",
        "\n",
        "# Save explanation to HTML file for sharing\n",
        "html = exp.as_html()\n",
        "with open(\"lime_explanation_idx5.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(html)\n",
        "\n"
      ],
      "metadata": {
        "id": "0KEim0CXapvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6RJ0u9sTawBp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}